# -*- coding: utf-8 -*-
"""Crime Data Analysis & Cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nH6rVLFRjsr0BhbM5ajG9AF69fTKPFEy

# **UK Police Crime Dataset Jan 2025 - Sept 2025 : Data Cleaning and Analysis(step 2)**

---

**Name :** Shikha Tyagi

***MSc Business Analytics***

**Student ID:** 20052009

**Dissertation Topic:** Crime Hotspot Detection Using Geospatial
Visualisation and Unsupervised Clustering : A*n Unsupervised Learning Approach on UK Open Crime Data*


**Dataset link:**

https://drive.google.com/file/d/1aX3KbyVYvCTbKdlUWbfsO3XIwIbWfWGy/view?usp=drive_link
"""

# Loading important libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Loading FINAL merged dataset
file_path = "/content/Street_to_Outcomes_Merged_final.csv"
df = pd.read_csv(file_path)

print("Dataset Loaded Successfully!")
print("Shape:", df.shape) # checking number of rows and columns

"""***Basic Structure and info***"""

print("\n--- Dataset Info ---")
print(df.info())

print("\n--- First 5 Rows ---")
print(df.head())

print("\n--- Summary Statistics ---")
print(df.describe(include='all'))

"""***Missing Values Analysis***"""

# vizulasing number of missing values in each columns in a bar graph
print("\n--- Missing Values Count ---")
missing = df.isna().sum().sort_values(ascending=False)
print(missing)
import matplotlib.ticker as ticker

plt.figure(figsize=(12, 6))
missing.sort_values(ascending=False).head(15).plot(kind='bar')

plt.title("Columns with Missing Values", fontsize=14)
plt.xlabel("Columns", fontsize=12)
plt.ylabel("Number of Missing Values", fontsize=12)

plt.gca().yaxis.set_major_formatter(
    ticker.FuncFormatter(lambda x, pos: f'{int(x):,}')
)

plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""***Unique Values Overview***"""

print("\n--- Unique Values in Columns ---")
print(df.nunique().sort_values(ascending=False))

"""***Crime Type Distribution***"""

# vizualizing the crime type across the dataset
plt.figure(figsize=(12, 6))

crime_counts = df['crime type'].value_counts()
crime_counts.plot(kind='bar')

plt.title("Crime Type Distribution", fontsize=14)
plt.xlabel("Crime Type", fontsize=12)
plt.ylabel("Number of Incidents", fontsize=12)

plt.gca().yaxis.set_major_formatter(
    ticker.FuncFormatter(lambda x, pos: f'{int(x):,}')
)

plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""***Monthly Crime Trend***"""

# vizualizing the crime trend over the period Jan 2025 - Sept 2025
df['month'] = pd.to_datetime(df['month'], errors='coerce')

monthly_trend = df.groupby(df['month'].dt.to_period('M')).size()

monthly_trend.plot(kind='line', figsize=(12,6))
plt.title("Crime Trend Over Time (Monthly)")
plt.ylabel("Crime Count")
plt.show()

"""***Outcome Category Distribution***"""

# Vizualizing outcome types for number of cases
plt.figure(figsize=(14, 6))

outcome_counts = df['outcome_type'].value_counts()
x_pos = np.arange(len(outcome_counts))

plt.bar(x_pos, outcome_counts.values)

plt.title("Top Outcome Types", fontsize=14)
plt.xlabel("Outcome Type", fontsize=12)
plt.ylabel("Number of Cases", fontsize=12)

plt.xticks(x_pos, outcome_counts.index, rotation=45, ha='right')

plt.gca().yaxis.set_major_formatter(
    ticker.FuncFormatter(lambda x, pos: f'{int(x):,}')
)

plt.tight_layout()
plt.show()

"""***Checking Location Data Quality***"""

# geospatial vizualiation with missing coordinates
print("\nLatitude missing:", df['latitude'].isna().sum())
print("Longitude missing:", df['longitude'].isna().sum())

plt.figure(figsize=(10,5))
sns.scatterplot(x='longitude', y='latitude', data=df.sample(5000))
plt.title("Sample of Crime Locations")
plt.show()

"""***Outlier Analysis (Latitude / Longitude)***"""

# vizualizing latitude/longiude outliers
plt.figure(figsize=(12,5))
sns.boxplot(data=df[['latitude', 'longitude']])
plt.title("Latitude & Longitude Outlier Check")
plt.show()

"""***Correlation Heatmap***"""

# vizualizing correlation
num_cols = df.select_dtypes(include=['float64', 'int64']).columns

plt.figure(figsize=(10,8))
sns.heatmap(df[num_cols].corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

"""***Crimes per LSOA (Local Area Analysis)***


"""

#Locating top crime location
top_lsoa = df['lsoa name'].value_counts().head(20)

plt.figure(figsize=(12,6))
top_lsoa.plot(kind='bar')
plt.title("Crime Areas (LSOA)")
plt.xlabel("LSOA")
plt.xticks(ha='right')
plt.ylabel("Crime Count")
plt.xticks(rotation=75)
plt.show()

"""# **Cleaning the data**"""

# Start cleaning

# 1. Drop useless column
df = df.drop(columns=['context'], errors='ignore')
# 2. Drop rows where crime_id is missing
df = df[df['crime_id'].notna()]
# 3. Drop rows where latitude or longitude is missing
df = df[df['latitude'].notna() & df['longitude'].notna()]

# 4. Fix data types
df['crime_id'] = df['crime_id'].astype(str).str.strip()
df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')
df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')
df['month'] = pd.to_datetime(df['month'], errors='coerce')

# 5. Remove any rows where month could not convert
df = df[df['month'].notna()]

# 6. Remove duplicates
df = df.drop_duplicates()

# 7.Fill meaningful missing values
df['last outcome category'] = df['last outcome category'].fillna("Outcome Pending")
df['outcome_type'] = df['outcome_type'].fillna("No Outcome Recorded")
df['lsoa code'] = df['lsoa code'].fillna("NaN")
df['lsoa name'] = df['lsoa name'].fillna("NaN")
df = df[(df['latitude'] != 0) & (df['longitude'] != 0)]
df = df[(df['latitude'] >= 49) & (df['latitude'] <= 61)]
df = df[(df['longitude'] >= -8) & (df['longitude'] <= 2)]

print(" Cleaned dataset shape:", df.shape)

# Check missing values again
df.isna().sum()
df.to_csv("/content/Cleaned_crime_data.csv", index=False) # Saving cleaned crime data for furthur analysis and clustering

"""***Basic info about cleaned dataset***"""

df.info()
df.describe()

"""***Vizualisation with cleaned dataset***"""

# Crime Trend for clean dataset
df['month'] = pd.to_datetime(df['month'], errors='coerce')

monthly_trend = df.groupby(df['month'].dt.to_period('M')).size()

monthly_trend.plot(kind='line', figsize=(12,6))
plt.title("Crime Trend Over Time (Monthly) of cleaned dataset")
plt.ylabel("Crime Count")
plt.show()

# Scatter plot for cleaned crime dataset
print("\nLatitude missing:", df['latitude'].isna().sum())
print("Longitude missing:", df['longitude'].isna().sum())

plt.figure(figsize=(10,5))
sns.scatterplot(x='longitude', y='latitude', data=df.sample(5000))
plt.title("Sample of Crime Locations for cleaned dataset")
plt.show()